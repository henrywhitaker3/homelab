# Default values for redeployer.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

image:
  repository: bitnami/kubectl
  pullPolicy: Always
  # Overrides the image tag whose default is the chart appVersion.
  tag: latest

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

role:
  name: restart-deployment

jobs:
  - name: overseerr
    command: kubectl -n media rollout restart deployment overseerr
    schedule: "0 4 * * *"
  - name: organizr
    command: kubectl -n media rollout restart deployment organizr
    schedule: "0 4 * * *"
  - name: kuma
    command: kubectl -n monitoring rollout restart deployment uptime-kuma
    schedule: "0 4 * * *"
  - name: rebalanace-plex
    schedule: "*/5 * * * *"
    command: |
      #!/bin/bash

      nodes=$(kubectl get nodes -l quicksync -o json | jq -r '.items[].metadata.name')
      current_node=$(kubectl -n media get pod -l app.kubernetes.io/name=plex -o json | jq -r '.items[0].spec.nodeName')

      for node in $nodes; do
        if [ $current_node == $node ]; then
          echo Plex running on preferred node
          exit 0
        fi
      done

      echo Plex not running on preferred node

      ready=$(kubectl get nodes -l quicksync | grep -E "(.*)\s+(Ready|NotReady)\s+(control-plane|<none>)" | cut -d' ' -f 1)
      for node in $ready; do
        echo Preferred node available
        kubectl -n media rollout restart deployment plex
        exit 0
      done

      echo Preferred node unavailable
      exit 0
  - name: kill-prowlarr
    schedule: "*/5 * * * *"
    command: |
      #!/bin/bash

      unavailable=$(kubectl -n media get deployment -l app.kubernetes.io/instance=prowlarr -o json | jq -r '.items[0].status.unavailableReplicas')

      if [ $unavailable != null ]; then
        echo Status is not running. Waiting 120 seconds...
        sleep 120
        unavailable=$(kubectl -n media get deployment -l app.kubernetes.io/instance=prowlarr -o json | jq -r '.items[0].status.unavailableReplicas')
        if [ $unavailable != null ]; then
          echo Status still not running, deleting pods
          kubectl -n media delete pod -l app.kubernetes.io/instance=prowlarr
        fi
      else
          echo Status is healthy
      fi
