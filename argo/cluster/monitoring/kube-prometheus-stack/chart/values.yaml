namespaceOverride: monitoring

alertmanager:
  enabled: true

  config:
    route:
      group_by:
        - alertname
      routes:
        - receiver: heartbeat
          group_interval: 5m
          group_wait: 0s
          matchers:
            - alertname =~ "Watchdog"
          repeat_interval: 5m
        - receiver: discord
          matchers:
            - severity = critical
        - receiver: discord_warn
          matchers:
            - severity = warning
    receivers:
      - name: "null"
      - name: heartbeat
      - name: discord_warn
        slack_configs:
          - api_url_file: /etc/alertmanager/secrets/alertmanager-secrets/slack_warn
            send_resolved: true
      - name: discord
        slack_configs:
          - api_url_file: /etc/alertmanager/secrets/alertmanager-secrets/slack
            send_resolved: true

  alertmanagerSpec:
    replicas: 2
    secrets:
      - alertmanager-secrets

  ingress:
    enabled: true

    annotations:
      kubernetes.io/tls-acme: "true"
      cert-manager.io/cluster-issuer: letsencrypt-prod
      nginx.ingress.kubernetes.io/auth-url: https://auth.plexmox.com/api/verify
      nginx.ingress.kubernetes.io/auth-signin: https://auth.plexmox.com

    hosts:
      - alerts.plexmox.com

    tls:
      - secretName: alerts-plexmox-com-tls
        hosts:
          - alerts.plexmox.com

nodeExporter:
  enabled: false

kubeEtcd:
  enabled: true
  endpoints:
    - 10.0.0.20
    - 10.0.0.21
    - 10.0.0.24

kubeControllerMnager:
  enabled: true
  endpoints:
    - 10.0.0.20
    - 10.0.0.21
    - 10.0.0.24

kubeProxy:
  enabled: true
  endpoints:
    - 10.0.0.20
    - 10.0.0.21
    - 10.0.0.24

kubeScheduler:
  enabled: true
  endpoints:
    - 10.0.0.20
    - 10.0.0.21
    - 10.0.0.24

defaultRules:
  rules:
    kubeControllerManager: false
    kubeProxy: false
    kubeSchedulerAlerting: false
    kubeSchedulerRecording: false

additionalPrometheusRulesMap:
  misc:
    groups:
      - name: vms
        rules:
          - alert: VMDown
            expr: 100 * (count by (instance) (up{job="node_exporter"} == 0) / count by (instance) (up{job="node_exporter"})) > 10
            for: 5m
            labels:
              severity: critical
            annotations:
              summary: Target {{ $labels.instance }} is DOWN
      - name: k8s
        rules:
          - alert: OOMKilled
            expr: (kube_pod_container_status_restarts_total - kube_pod_container_status_restarts_total offset 10m >= 1) and ignoring (reason) min_over_time(kube_pod_container_status_last_terminated_reason{reason="OOMKilled"}[10m]) == 1
            labels:
              severity: critical
            annotations:
              summary: Container {{ $labels.container }} in pod {{ $labels.namespace }}/{{ $labels.pod }} has been OOMKilled {{ $value }} times in the last 10 minutes.
      - name: haproxy
        rules:
          - alert: HaproxyServerNotUp
            expr: haproxy_server_status{state!="UP"} > 0
            for: 3m
            labels:
              severity: critical
            annotations:
              summary: Haproxy Server {{ $labels.server }} is not UP for backend {{ $labels.proxy }}
      - name: argo
        rules:
          - alert: ArgocdServiceUnhealthy
            expr: argocd_app_info{health_status!="Healthy"} != 0
            for: 15m
            labels:
              severity: warning
            annotations:
              summary: ArgoCD service unhealthy (instance {{ $labels.instance }})
          - alert: ArgocdServiceNotSynced
            expr: argocd_app_info{sync_status!="Synced"} != 0
            for: 15m
            labels:
              severity: warning
            annotations:
              summary: ArgoCD service not synced (instance {{ $labels.instance }})
      - name: db
        rules:
          - alert: MysqlDown
            expr: mysql_up{service!~"srep.*"} == 0
            for: 0m
            labels:
              severity: critical
            annotations:
              summary: MySQL down (instance {{ $labels.instance }})
          - alert: MysqlHighThreadsRunning
            expr: max_over_time(mysql_global_status_threads_running{service!~"srep.*"}[1m]) / mysql_global_variables_max_connections{service!~"srep.*"} * 100 > 75
            for: 2m
            labels:
              severity: warning
            annotations:
              summary: MySQL high threads running (instance {{ $labels.instance }})
          - alert: RedisDown
            expr: redis_up{service!~"srep*"} == 0
            for: 0m
            labels:
              severity: critical
            annotations:
              summary: Redis down (instance {{ $labels.instance }})
  srep:
    groups:
      - name: api
        rules:
          - alert: APIErrorRate
            expr: ((rate(srep_requests_total{code=~"2..|4..|3.."}[1m]) / rate(srep_requests_total[1m])) * 100) < 99.99
            for: 1m
            labels:
              severity: critical
            annotations:
              summary: API Success Rate is < 99.99%
          - alert: APIMysqlDown
            expr: mysql_up{service="srep-mysql"} == 0
            for: 0m
            labels:
              severity: critical
            annotations:
              summary: API MySQL is down
          - alert: APIMysqlHighThreadsRunning
            expr: max_over_time(mysql_global_status_threads_running{service="srep-mysql"}[1m]) / mysql_global_variables_max_connections{service="srep-mysql"} * 100 > 75
            for: 2m
            labels:
              severity: warning
            annotations:
              summary: MySQL high threads running (instance {{ $labels.instance }})
          - alert: APIRedisDown
            expr: redis_up{service="srep-redis"} == 0
            for: 0m
            labels:
              severity: critical
            annotations:
              summary: Redis down (instance {{ $labels.instance }})

grafana:
  enabled: true

  admin:
    existingSecret: grafana-creds

  ingress:
    enabled: true

    annotations:
      kubernetes.io/tls-acme: "true"
      cert-manager.io/cluster-issuer: letsencrypt-prod
      nginx.ingress.kubernetes.io/auth-url: https://auth.plexmox.com/api/verify
      nginx.ingress.kubernetes.io/auth-signin: https://auth.plexmox.com

    hosts:
      - grafana.plexmox.com

    tls:
      - secretName: grafana-plexmox-com-tls
        hosts:
          - grafana.plexmox.com

  sidecar:
    dashboards:
      folderAnnotation: grafana_folder
      provider:
        foldersFromFilesStructure: true

  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
        - name: default
          orgId: 1
          folder: Custom
          type: file
          disableDeletion: true
          editable: false
          options:
            path: /var/lib/grafana/dashboards/default

  dashboards:
    default:
      haproxy:
        gnetId: 12693
        revision: 7
        datasource: Prometheus
      node_exporter:
        gnetId: 1860
        revision: 33
        datasource: Prometheus
      argocd:
        gnetId: 14584
        revision: 1
        datasource: Prometheus
      cert-manager:
        gnetId: 11001
        revision: 1
        datasource: Prometheus
      ingress-nginx:
        gnetId: 9614
        revision: 1
        datasource: Prometheus
      mysql-overview:
        gnetId: 14057
        revision: 1
        datasource: Prometheus
      golang:
        gnetId: 14061
        revision: 1
        datasource: Prometheus
      redis:
        gnetId: 14091
        revision: 1
        datasource: Prometheus

  additionalDataSources:
    - name: Loki
      ordId: 1
      access: proxy
      type: loki
      url: http://loki-gateway
      jsonData:
        maxLines: 250

prometheus:
  ingress:
    enabled: true

    annotations:
      kubernetes.io/tls-acme: "true"
      cert-manager.io/cluster-issuer: letsencrypt-prod
      nginx.ingress.kubernetes.io/auth-url: https://auth.plexmox.com/api/verify
      nginx.ingress.kubernetes.io/auth-signin: https://auth.plexmox.com

    hosts:
      - prometheus.plexmox.com

    tls:
      - secretName: prometheus-plexmox-com-tls
        hosts:
          - prometheus.plexmox.com

  persistentVolume:
    enabled: true
    size: 50Gi
    storageClass: longhorn

  prometheusSpec:
    scrapeConfigSelectorNilUsesHelmValues: false
    ruleSelectorNilUsesHelmValues: false
    serviceMonitorSelectorNilUsesHelmValues: false
    podMonitorSelectorNilUsesHelmValues: false
    probeSelectorNilUsesHelmValues: false

    retention: 7d

    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: longhorn
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 50Gi
